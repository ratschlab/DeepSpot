{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ffba161",
   "metadata": {},
   "source": [
    "# Inference of DeepSpot2Cell on H&E Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da552ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from deepspot.deepspot2cell import DeepSpot2Cell\n",
    "from deepspot.utils import get_morphology_model_and_preprocess, predict_spot2cell_from_image_paths\n",
    "\n",
    "\n",
    "cell_image_path = \"path/to/cell_image.png\"\n",
    "spot_image_path = \"path/to/spot_image.png\"\n",
    "neighbor_images_paths = [\"path/to/neighbor_image1.png\", \"path/to/neighbor_image2.png\", \"path/to/neighbor_image3.png\", \"path/to/neighbor_image4.png\"]\n",
    "model_checkpoint = \"results/final_model.pt\"\n",
    "gene_names_path = \"path/to/gene_names.json\"  # Optional\n",
    "morphology_model_path = \"path/to/phikonv2/model\"\n",
    "output_size = 1000  # Number of genes in the dataset\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load gene names (optional)\n",
    "gene_names = None\n",
    "if gene_names_path and os.path.exists(gene_names_path):\n",
    "    with open(gene_names_path, 'r') as f:\n",
    "        gene_names = json.load(f)\n",
    "\n",
    "# Load morphology model\n",
    "morphology_model, preprocess, input_size = get_morphology_model_and_preprocess(\"phikonv2\", device, model_path=morphology_model_path)\n",
    "morphology_model.to(device)\n",
    "morphology_model.eval()\n",
    "\n",
    "# Load DeepSpot2Cell model\n",
    "deepspot_model = DeepSpot2Cell(input_size=input_size, output_size=output_size)\n",
    "checkpoint = torch.load(model_checkpoint, map_location=device)\n",
    "deepspot_model.load_state_dict(checkpoint)\n",
    "deepspot_model.to(device)\n",
    "deepspot_model.eval()\n",
    "print(f\"Models loaded successfully. Input size: {input_size}, Output size: {output_size}\")\n",
    "\n",
    "predictions = predict_spot2cell_from_image_paths(\n",
    "    cell_image_path=cell_image_path,\n",
    "    spot_image_path=spot_image_path,\n",
    "    neighbor_image_paths=neighbor_images_paths,\n",
    "    deepspot2cell_model=deepspot_model,\n",
    "    morphology_model=morphology_model,\n",
    "    preprocess=preprocess,\n",
    "    device=device,\n",
    "    gene_names=gene_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166256d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTop expressed genes:\")\n",
    "for gene, value in sorted(predictions.items(), key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print(f\"{gene}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
